---
title: LLM Integration
description: Provider usage with automatic token management and Vercel AI SDK integration
---

import { Callout } from 'fumadocs-ui/components/callout';

# LLM Integration

Echo Next.js SDK provides async LLM providers that integrate seamlessly with Vercel AI SDK patterns while handling authentication automatically.

## Provider Architecture

### Async Provider Pattern

All providers return Promises for automatic token management:

```typescript
import Echo from '@merit-systems/echo-next-sdk';

const { openai, anthropic } = Echo({ appId: 'your-echo-app-id' });

// Model-specific providers
const gpt4 = await openai('gpt-4');
const claude = await anthropic('claude-4-sonnet');
```

<Callout type="info">
The async pattern enables automatic token refresh before each LLM call, ensuring requests never fail due to expired authentication.
</Callout>

### Available Providers

**OpenAI Provider:**
```typescript
const gpt4Model = await openai('gpt-4'); 
```

**Anthropic Provider:**
```typescript  
const claudeModel = await anthropic('claude-4-sonnet'); // Specific model
```

## Vercel AI SDK Integration

### Streaming Text Generation

```typescript title="app/api/chat/route.ts"
import Echo from '@merit-systems/echo-next-sdk';
import { streamText } from 'ai';

const { openai } = Echo({ appId: 'your-echo-app-id' });

export async function POST(req: Request) {
  const { messages } = await req.json();
  
  const result = streamText({
    model: await openai('gpt-4'),
    messages,
    temperature: 0.7,
  });
  
  return result.toUIMessageStreamResponse();
}
```

### Object Generation

```typescript title="app/api/extract/route.ts"
import { openai } from '@merit-systems/echo-next-sdk';
import { generateObject } from 'ai';
import { z } from 'zod';

const schema = z.object({
  name: z.string(),
  age: z.number(),
  location: z.string(),
});

export async function POST(req: Request) {
  const { text } = await req.json();
  
  const result = await generateObject({
    model: await openai('gpt-4'),
    prompt: `Extract person info from: ${text}`,
    schema,
  });
  
  return Response.json(result.object);
}
```

### Text Generation

```typescript title="app/api/generate/route.ts"
import { anthropic } from '@merit-systems/echo-next-sdk';
import { generateText } from 'ai';

export async function POST(req: Request) {
  const { prompt } = await req.json();
  
  const { text } = await generateText({
    model: await anthropic('claude-4-sonnet'),
    prompt,
    maxTokens: 1000,
  });
  
  return Response.json({ text });
}
```

### Image Generation

```typescript title="app/api/generate/route.ts"
import { openai } from '@echo'
import { generateImage } from 'ai';

export async function POST(req: Request) {
  const { prompt } = await req.json();
  
  const { image } = await generateImage({
    model: await openai.image('gpt-image-1'),
    prompt,
  });
  
  return Response.json({ image });
}
```
